import requests
import os
import re
from tqdm import tqdm

try:
    from config import settings as actual_settings
    settings = actual_settings
except ImportError:
    print("Aviso: N칚o foi poss칤vel importar 'config.settings'. Usando placeholders. Certifique-se que 'config.py' est치 acess칤vel.")
try:
    from views.fetcher import fetch_all_pages, save_pages
    pass 
except ImportError:
    print("Aviso: N칚o foi poss칤vel importar de 'views.fetcher'. As fun칞칫es definidas localmente ser칚o usadas.")


email = settings.EMAIL
api_token = settings.API_TOKEN
save_folder = settings.HTML_DOCS_PATH 
base_url = settings.BASE_URL
space_keys = [
    "EMS", "OMS", "OPA", "PMS", "POS", "WSS", "Hstays", "WIKI",
    "CMSupE", "CMSup", "hpn", "pneng", "pnsup", "CRS", "CST",
    "CM", "CME", "HE", "HEYC", "ags", "API", "PDOC", "PDP", "MAN"
]
auth = (email, api_token)

os.makedirs(save_folder, exist_ok=True)

def clean_filename(name):
    name = re.sub(r'[<>:"/\\|?*\t]', '_', name)
    name = name.replace(';', '_')
    return name

def fetch_all_pages(space_key):
    start = 0
    limit = 50
    pages = []

    print(f"Buscando p치ginas para o espa칞o {space_key}...")
    while True:
        url = f"{base_url}/rest/api/content?spaceKey={space_key}&limit={limit}&start={start}&expand=body.storage"
        try:
            response = requests.get(url, auth=auth, timeout=30)
            response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        except requests.exceptions.RequestException as e:
            print(f"Erro de conex칚o ao buscar p치ginas para o espa칞o {space_key}: {e}")
            break

        try:
            data = response.json()
        except requests.exceptions.JSONDecodeError:
            print(f"Erro ao decodificar JSON da resposta para o espa칞o {space_key}. Conte칰do: {response.text}")
            break
        
        current_pages = data.get('results', [])
        pages.extend(current_pages)

        if not current_pages or len(current_pages) < limit:
            break

        start += limit
    print(f"Total de {len(pages)} p치ginas encontradas para {space_key}.")
    return pages

def save_pages(pages, space_key):

    space_specific_folder = os.path.join(save_folder, space_key)
    os.makedirs(space_specific_folder, exist_ok=True)
    
    saved_count = 0
    skipped_count = 0

    for page in tqdm(pages, desc=f"Salvando p치ginas do espa칞o {space_key}"):
        title = clean_filename(page['title'])
        file_path = os.path.join(space_specific_folder, f"{title}.html")

        if os.path.exists(file_path):
            skipped_count += 1
            continue
        try:
            body_html = page['body']['storage']['value']
        except (KeyError, TypeError):
            print(f"Aviso: Corpo HTML n칚o encontrado ou em formato inesperado para a p치gina '{title}' no espa칞o {space_key}. Pulando.")
            continue

        try:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(body_html)
            saved_count += 1
        except IOError as e:
            print(f"Erro ao salvar o arquivo {file_path}: {e}")
            
    print(f"Para o espa칞o {space_key}: {saved_count} p치ginas salvas, {skipped_count} p치ginas puladas (j치 existentes).")

def download_main():
    for space_key in space_keys:
        print(f"\n游댌 Processando espa칞o: {space_key}")
        pages = fetch_all_pages(space_key)
        if pages:
            save_pages(pages, space_key)
        else:
            print(f"Nenhuma p치gina para salvar para o espa칞o {space_key}.")
    print("\nDownload de todas as p치ginas conclu칤do.")